---
permalink: /
layout: page
title: Welcome
---

Hi, I am Alex Falcon. I am a Post-doc researcher at the [University of Udine](https://www.uniud.it/it) ([AI Lab](http://ailab.uniud.it/)). I completed my PhD in Computer Science, Mathematics and Physics, jointly held at [Fondazione Bruno Kessler](https://www.fbk.eu/it/) ([Technology of Vision - TeV](https://tev.fbk.eu/)) and University of Udine, under the supervision of [Oswald Lanz](https://www.unibz.it/it/faculties/engineering/academic-staff/person/46208-oswald-lanz) (Free University of Bolzano) and [Giuseppe Serra](https://people.uniud.it/page/giuseppe.serra) (University of Udine). My main research focus is currently focused towards multimedia, video and language understanding, and deep learning. Before that, I completed my Bachelor's and Master's degree in Computer Science at the University of Udine. Specifically, during my Master's I started working with AI, machine learning, and deep learning with a focus on Predictive Maintenance.

E-mail: falcon.alex 'at' spes.uniud.it / [Google Scholar](https://scholar.google.com/citations?user=sHPhexYAAAAJ&hl=it) / [Github](https://github.com/aranciokov) / [LinkedIn](https://www.linkedin.com/in/alex-falcon-9b1a231a3) / [CV](https://github.com/aranciokov/aranciokov.github.io/blob/master/CV-1.pdf)

<h3><span class="fa-solid fa-bullhorn fa-bounce"></span> News <span class="fa-solid fa-bullhorn fa-bounce"></span></h3>
<ul>
  <li>I was an invited teacher for the <a href="https://training.itineris.cnr.it/en/categories/phds-and-masters/resource/artificial_intelligence_and_data_mining_methods_in_ecology/">Artificial intelligence and data mining methods in ecology</a> PhD course held within ITINERIS!</li>
  <li>one paper accepted at IJDL! [open access paper soon]</li>
  <li>two journal papers on multidisciplinary collaborations were recently accepted on <b><a href="https://www.tandfonline.com/doi/full/10.1080/19475683.2025.2523737">Annals of GIS</a></b> and <b><a href="https://www.mdpi.com/2072-6643/17/13/2196">Nutrients</a></b>!!</li>
  <li>one paper accepted at ICIAP!</li>
  <li>two papers (one <a href="https://doi.org/10.1145/3731715.3733358">full paper</a> based on work of my MSc students + one <a href="https://doi.org/10.1145/3731715.3734535">reproducibility</a>) accepted at <b>ACM ICMR 2025</b>!</li>
  <li>won a MIT GSF grant (about $25k) and one NRRP grant for €250k!!!</li>
  <li>one paper accepted at <b>IEEE Transactions on Multimedia</b>!! [open access paper soon]</li>
  <li>one paper accepted at <b><a href="https://www.sciencedirect.com/science/article/pii/S2589721725000303">Artificial Intelligence in Agriculture</a></b>!!</li>
  <li>check this report we published at <a href="https://dl.acm.org/doi/abs/10.1145/3722449.3722456">ACM SIGIR Forum!</a></li>
  <li>I'm part of the organization for the <a href="https://sites.google.com/view/cv4metaverse-2025">4th ed. of CV4Metaverse at <b>CVPR 2025</b></a>! See you in Nashville, Tennessee! <a href="https://sites.google.com/view/cv4metaverse-2025/call-for-papers">[CFP (DL: March 22!)]</a></li>
  <li>one paper accepted at <a href="https://ircdl2025.uniud.it">IRCDL</a>! <a href="https://ceur-ws.org/Vol-3937/paper16.pdf">[pdf]</a></li>
  <li>one paper accepted at <a href="https://mmm2025.net/">MMM 2025</a>! See you in Nara, Japan! <a href="https://link.springer.com/chapter/10.1007/978-981-96-2061-6_5">[link]</a> <a href="https://github.com/aranciokov/HierArtEx-MMM2025">[code]</a></li>
  <li>I was nominated <b>Outstanding Reviewer</b> (<a href="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/refs/heads/master/assets/imgs/OR_ECCV2024.jpeg">198</a> out of almost <a href="https://pbs.twimg.com/media/GYyO1V8WUAEfFM4?format=jpg&name=large">7300</a> reviewers!) at <b>ECCV 2024</b>!!! <a href="https://eccv2024.ecva.net/Conferences/2024/Reviewers">[link]</a></li>
  <li>one paper accepted at <b><a href="https://www.sciencedirect.com/science/article/pii/S1574954124003704">Ecological Informatics</a></b>!!</li>
  <li>I'm part of the organization committee for <a href="https://ircdl2025.uniud.it/">IRCDL 2025</a>!</li>
  <li>EQAI 2024 was featured on a <a href="https://www.udinetoday.it/cronaca/uniud-scuola-estiva-ai-quantum-computing.html">local newspaper</a>! Everything is ready for this September!</li>
  <li>I was invited as a <a href="https://www.aidlda.it/speaker/alex-falcon/">speaker</a> at the AI-DLDA summer school, where I talked about retrieving complex 3D scenarios using text! A notebook will become available later on!</li>
  <li>one paper accepted at <b><a href="https://doi.org/10.1016/j.cviu.2024.104035">Computer Vision and Image Understanding</a></b>!!! <a href="https://github.com/aranciokov/ranp/">[code]</a> </li>
  <li>one paper accepted as Poster at <a href="https://dl.acm.org/doi/abs/10.1145/3652583.3658039"><b>ACM ICMR 2024</b></a>! See you in Phuket, Thailand!</li>
  <li>We are organizing the <b><a href="https://sites.google.com/view/cv4metaverse-2024">3rd ed. of CV4Metaverse workshop at ECCV 2024</a></b> and hosting the <i class="fa-solid fa-ranking-star"></i> <a href="https://ailab.uniud.it/apartment-recommendation-challenge/">Metaverse Apartment Retrieval Challenge</a>!</li>
  <li>I am part of the local organization committee for <a href="http://eqai.eu/">EQAI 2024 (European Summer School on Quantum AI)</a>!</li>
  <li>I am a guest editor for the <b>Special Issue on Text-Multimedia Retrieval: Retrieving Multimedia Data by Means of Natural Language</b> at <b>ACM TOMM</b>! Check the <a href="https://dl.acm.org/pb-assets/static_journal_pages/tomm/pdf/ACM_SI_Text_Multimedia_Retrieval-1708635324153.pdf">call for papers</a>! (deadline: June 30, 2024)</li>
  <li>one paper accepted as an Oral at <a href="https://ceur-ws.org/Vol-3643/paper17.pdf">IRCDL 2024</a>!</li>
 </ul>
<details>
<summary>[click for previous years]</summary>
<ul>
 <li><em>2023</em></li>
 <ul>
  <li>one paper accepted as an Oral at <a href="https://link.springer.com/chapter/10.1007/978-3-031-53311-2_35"><b>MMM 2024</b></a>! <a href="https://github.com/aliabdari/NLP_to_rank_artistic_Metaverses">code by Ali</a></li>
  <li>one paper accepted at <a href="https://dl.acm.org/doi/abs/10.1145/3606040.3617445">MMIR@<b>ACM MM 2023</b></a> and one paper accepted at <a href="https://openaccess.thecvf.com/content/ICCV2023W/CV4Metaverse/html/Abdari_FArMARe_a_Furniture-Aware_Multi-Task_Methodology_for_Recommending_Apartments_Based_on_ICCVW_2023_paper.html">CV4Metaverse@<b>ICCV 2023</b></a>! Codebases by Ali: <a href="https://github.com/aliabdari/Metaverse_Retrieval">code1</a> <a href="https://github.com/aliabdari/FArMARe">code2</a></li>
  <li>I had a great experience at the <a href="https://www.ellis.unimore.it/summer-school/"><b>ELLIS Summer School on Large-Scale AI for Research and Industry</b></a> in Modena, Italy!</li>
  <li><a href="https://link.springer.com/chapter/10.1007/978-3-031-43153-1_16">one paper</a> accepted at ICIAP 2023!</li>
  <li><a href="https://arxiv.org/abs/2306.15445">our solution (report)</a>, trained with only 25% of the data, got <b>3rd place</b> in the EPIC-Kitchens-100 Multi-Instance Retrieval Challenge @ CVPR 2023!</li>
  <li>I am part of the local organization committee for <a href="https://iciap2023.org/">ICIAP 2023</a>!</li>
  <li>I delivered a seminar on "Deep Learning for Multimedia understanding" as the speaker at University of Udine!</li>
  <li>I am part of the local organization committee for the <a href="http://eqai.eu/"><b>2nd edition of the European Summer School on Quantum AI</b></a>!</li>
  <li>March, 13th 2023: I successfully defended my <a href="https://air.uniud.it/handle/11390/1252364"><b>PhD thesis</b></a> <em>cum laude</em>!</li>
  <li><a href="https://link.springer.com/article/10.1007/s11042-023-14333-0">one paper</a> accepted at <b>Multimedia Tools and Applications</b>! <a href="https://github.com/aranciokov/MT-VideoQA">code</a></li>
 </ul>
 <li><em>2022</em></li>
 <ul>
  <li><a href="https://ceur-ws.org/Vol-3463/paper2.pdf">one paper (pdf)</a> accepted as an Oral at AIABI@AIxIA 2022!</li>
  <li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0166361522001592">one paper</a> accepted at <b>Computers in Industry</b>! <a href="https://github.com/aranciokov/NTM-For-RULEstimation">code</a></li>
  <li><a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548365">one paper</a> accepted as an Oral at <b>ACM MM 2022</b>! <a href="https://github.com/aranciokov/FSMMDA_VideoRetrieval">code</a></li>
  <li>I delivered two talks at University of Bolzano: "Data-driven approaches for the Remaining Useful Life Estimation problem" and "Learning video retrieval models with relevance-aware online mining"</li>
  <li>I was featured in the <a href="https://magazine.fbk.eu/it/news/un-riconoscimento-internazionale-per-la-comprensione-semantica-di-video/">FBK magazine</a> (<em>italian</em>)!</li>
  <li><a href="https://arxiv.org/abs/2206.10903">our solution (report)</a> got <img src="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/master/assets/imgs/trophy.png" alt="(trophy emoji)" width="16px" height="auto"> <b>1st place</b> <img src="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/master/assets/imgs/trophy.png" alt="(trophy emoji)" width="16px" height="auto"> in the EPIC-Kitchens-100 Multi-Instance Retrieval Challenge @ CVPR 2022!</li>
  <li>I attended the fantastic <a href="https://iplab.dmi.unict.it/icvss2022/"><b>International Computer Vision Summer School (ICVSS)</b></a> in Scicli, Italy and presented a <a href="https://github.com/aranciokov/aranciokov.github.io/blob/master/poster_ICVSS-1.pdf">poster</a> titled "Relevance-aware Online Mining for Video Retrieval"!</li>
  <li><a href="https://dl.acm.org/doi/abs/10.1145/3512527.3531395">one paper</a> accepted as an Oral at <b>ICMR 2022</b>! <a href="https://github.com/aranciokov/RelevanceMargin-ICMR22">code</a></li>
  <li><a href="https://link.springer.com/chapter/10.1007/978-3-031-06433-3_16">one paper</a> accepted as an Oral at ICIAP 2021! <a href="https://github.com/aranciokov/ranp">code</a></li>
  <li>I delivered a seminar on "Data-driven approaches for the remaining useful life estimation problem" as the speaker at FBK!</li>
  </ul>
<li><em>2021</em></li>
 <ul>
  <li><a href="https://arxiv.org/abs/2110.02902">our solution (report)</a> got 3rd place in the EPIC-Kitchens-100 Action Recognition Challenge @ CVPR 2021!</li>
  <li>I completed the "Fundamentals of Deep Learning for Multi-GPUs" course held by NVIDIA Deep Learning Institute!</li>
  <li>we organized the <a href="https://sites.google.com/view/viqa2020">VIQA</a> workshop @ ICPR 2020 (later merged into the <a href="https://sites.google.com/view/vtiur2020/">VTIUR</a> workshop)!</li>
  </ul>
 <li><em>2020</em></li>
 <ul>
  <li><a href="https://link.springer.com/chapter/10.1007/978-3-030-66415-2_33">one paper</a> accepted as an Oral at EPIC@ECCV 2020!</li>
  <li>I attended the "<a href="https://boracchi.faculty.polimi.it/teaching/Non-Matrix.htm">Machine Learning for non-matrix data</a>" summer school at Politecnico di Milano!</li>
  <li><a href="http://www.papers.phmsociety.org/index.php/phme/article/view/1227">one paper</a> accepted as an Oral at PHME 2020!</li>
  <li><a href="https://ieeexplore.ieee.org/document/9187043">one paper</a> accepted as an Oral at ICPHM 2020!</li>
  </ul>
 
<li><em>2019</em></li>
<ul>
  <li><a href="https://link.springer.com/chapter/10.1007/978-3-030-39905-4_7">one paper</a> accepted at IRCDL 2019!</li>
  <li>October 2019: I started my PhD under the supervision of Oswald Lanz and Giuseppe Serra!</li>
  <li>July 2019: I successfully completed the Master's Degree in Computer Science <em>cum laude</em>!</li>
 </ul>
 </ul>
</details>

<h2>Main projects and lines of research</h2>

<h3>Text-Video Retrieval <i class="fa-regular fa-file"></i> <i class="fa-solid fa-arrow-right"></i> <i class="fa-solid fa-video"></i></h3>
<h5><em>Topics: multimedia, cross-modal understanding, vision and language</em></h5>

<img src="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/master/assets/imgs/fsmmda.png" alt="Overview of the algorithm" width="50%" height="auto"/>
<p><b>TL;DR</b>: Text-video retrieval is a task requiring to rank a collection of videos based on their relevance to a user textual query, with low ranks representing highly relevant videos and vice versa. State-of-the-art video retrieval systems are obtained with contrastive learning techniques. However, contrastive learning techniques enforce constraints at training time which neglect that multiple videos may be relevant for the same caption, and vice versa. In this line of research, we focus on the importance of introducing semantic knowledge into the training process to overcome these limitations. The results obtained confirm our observations and hypotheses, and the learning strategies we proposed effectively overcome them (e.g., from about 36% nDCG to almost 60% on the challenging EPIC-Kitchens-100 dataset). </p>

<h5>Selected publications/endeavors</h5>

<ol>
  <li><em>Improving semantic video retrieval models by training with a relevance-aware online mining strategy.</em><br/><b>A. Falcon</b>, G. Serra, O. Lanz. <b>Computer Vision and Image Understanding 245, 104035. 2024.</b> <a href="https://www.sciencedirect.com/science/article/pii/S1077314224001164">[pdf]</a></li>
  <li><em>Semantics for vision-and-language understanding.</em><br/><b>A. Falcon</b>. PhD Thesis, 2023. <a href="https://air.uniud.it/bitstream/11390/1252364/2/PhD_thesis-4.pdf">[pdf]</a></li>
  <li><em>A Feature-space Multimodal Data Augmentation Technique for Text-video Retrieval.</em><br/><b>A. Falcon</b>, G. Serra, O. Lanz. <b>ACM MM 2022.</b> <a href="https://arxiv.org/abs/2208.02080">[pdf]</a></li>
  <li><em>UniUD-FBK-UB-UniBZ Submission to the EPIC-Kitchens-100 Multi-Instance Retrieval Challenge 2022. (ranked <img src="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/master/assets/imgs/trophy.png" alt="(trophy emoji)" width="16px" height="auto"> <b>ranked 1st</b> <img src="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/master/assets/imgs/trophy.png" alt="(trophy emoji)" width="16px" height="auto">)</em><br/><b>A. Falcon</b>, G. Serra, S. Escalera, O. Lanz. <b>EPIC@CVPR 2022.</b> <a href="https://arxiv.org/abs/2206.10903">[pdf]</a></li>
  <li><em>Relevance-based margin for contrastively-trained video retrieval models.</em><br/><b>A. Falcon</b>, S. Sudhakaran, G. Serra, S. Escalera, O. Lanz. <b>ACM ICMR 2022.</b><a href="https://dl.acm.org/doi/abs/10.1145/3512527.3531395">[pdf]</a></li>
  <li><em>Learning video retrieval models with relevance-aware online mining.</em><br/><b>A. Falcon</b>, G. Serra, O. Lanz. <b>ICIAP 2021.</b> <a href="https://arxiv.org/abs/2203.08688">[pdf]</a></li>
</ol>



<h3>Ranking complex 3D scenes <i class="fa-regular fa-file"></i> <i class="fa-solid fa-arrow-right"></i> <i class="fa-solid fa-cube"></i></h3>
<h5><em>topics: multimedia, cross-modal understanding, vision and language</em></h5>

<img src="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/master/assets/imgs/MMM24_overview.png" alt="Overview of the algorithm" width="50%" height="auto">
<p><b>TL;DR</b>: Nowadays, multiple enticing experiences are available in the Metaverse. Actually, there are lots of them and it is difficult to find those which are relevant for the user. Can we formalize this as a ranking problem? We introduced and evaluated state-of-the-art techniques in various scenarios related to complex 3D scenes, composed of multiple furnished rooms (e.g., in apartments) or containing many multimedia items (e.g., paintings in museums) which can affect the relevance. </p>


<h5>Selected publications/endeavors</h5>

<ol>
  <li><em>Hierarchical Vision-Language Retrieval of Educational Metaverse Content in Agriculture.</em><br/>A. Abdari, <b>A. Falcon</b>, G. Serra. <b>ICIAP 2025.</b> <a href="">[pdf soon]</a></li>
  <li><em>HM3: Hierarchical Modeling of Multimedia Metaverses on 10000 Thematic Museums via Theme-aware Contrastive Loss Function.</em><br/>G. Macrì, L. Bazzana, <b>A. Falcon</b>, G. Serra. <b>ACM ICMR 2025.</b> <a href="https://dl.acm.org/doi/10.1145/3731715.3733358">[pdf]</a></li>
  <li><em>Reproducibility Companion Paper: AdOCTeRA - Adaptive Optimization Constraints for Improved text-guided Retrieval of Apartments</em><br/>A. Abdari, <b>A. Falcon</b>, G. Serra. <b>ACM ICMR 2025.</b> <a href="https://dl.acm.org/doi/10.1145/3731715.3734535">[pdf]</a></li>
  <li><em>ALCER3D: Adaptive Learning Constraints for Enhanced Retrieval of Complex Indoor 3D Scenarios.</em><br/><b>A. Falcon</b>, A. Abdari, G. Serra. <b>(accepted for publication in March at) IEEE TMM 2025.</b><a href="">[pdf soon]</a> <a href="https://github.com/aliabdari/ALCER3D">[code]</a></li>
  <li><em>AgriMus: Developing Museums in the Metaverse for Agricultural Education</em><br/>A. Abdari, <b>A. Falcon</b>, G. Serra. <b>IRCDL 2025</b> <a href="https://ceur-ws.org/Vol-3937/paper16.pdf">[pdf]</a></li>
  <li><em>HierArtEx: Hierarchical Representations and Art Experts Supporting the Retrieval of Museums in the Metaverse.</em><br/><b>A. Falcon</b>, A. Abdari, G. Serra. <b>MMM 2025.</b><a href="https://link.springer.com/chapter/10.1007/978-981-96-2061-6_5">[pdf]</a> <a href="https://github.com/aranciokov/HierArtEx-MMM2025">[code]</a></li>
  <li><em>AdOCTeRA: Adaptive Optimization Constraints for improved Text-guided Retrieval of Apartments.</em><br/>A. Abdari, <b>A. Falcon</b>, G. Serra. <b>ACM ICMR 2024.</b> <a href="https://dl.acm.org/doi/abs/10.1145/3652583.3658039">[pdf]</a></li>
  <li><em>Paving the Way for Personalized Museums Tours in the Metaverse.</em><br/><b>A. Falcon</b>, B. Portelli, A. Abdari, G. Serra. <b>IRCDL 2024.</b> <a href="https://ceur-ws.org/Vol-3643/paper17.pdf">[pdf]</a></li>
  <li><em>A Language-based solution to enable Metaverse Retrieval.</em><br/>A. Abdari, <b>A. Falcon</b>, G. Serra. <b>MMM 2024.</b> <a href="https://arxiv.org/abs/2312.14630">[pdf]</a></li>
  <li><em>FArMARe: a Furniture-Aware Multi-task methodology for Recommending Apartments based on the user interests.</em><br/>A. Abdari, <b>A. Falcon</b>, G. Serra. <b>CV4Metaverse@ICCV 2023.</b> <a href="https://openaccess.thecvf.com/content/ICCV2023W/CV4Metaverse/html/Abdari_FArMARe_a_Furniture-Aware_Multi-Task_Methodology_for_Recommending_Apartments_Based_on_ICCVW_2023_paper.html">[pdf]</a></li>
  <li><em>Metaverse Retrieval: Finding the Best Metaverse Environment via Language.</em><br/> A. Abdari, <b>A. Falcon</b>, G. Serra. <b>MMIR@ACM MM 2023.</b> <a href="https://dl.acm.org/doi/abs/10.1145/3606040.3617445">[pdf]</a></li>
</ol>




<h3>Applied AI for Multidisciplinary Problems <i class="fa-solid fa-building-wheat"></i> <i class="fa-solid fa-tree"></i> <i class="fa-solid fa-wine-bottle"></i> <i class="fa-solid fa-bowl-rice"></i></h3>
<h5><em>topics: real world data, machine learning for ecological problems, sustainability, computer vision for nutrition, computer vision for agriculture </em></h5>

<img src="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/master/assets/imgs/forestry_pipeline.png" alt="Example of pipeline for dealing with forestry data" width="50%" height="auto">
<p><b>TL;DR</b>: Dealing with multidisciplinary problems means dealing with real world data. This raises additional challenges (eg: data becomes more scarce or lower quality), and requires a different mindset to solve the problem at hand. Nonetheless, this also means dealing with problems that might have an impact on real issues, such as more sustainable farming techniques. I've had the opportunity of collaborating on several projects dealing with experts from heterogeneous fields including forestry, wine production, agriculture, and nutrition. </p>


<h5>Selected publications/endeavors</h5>

<ol>
  <li><em>Evaluating organic carbon in living and dead trees using GLCM features and explainable machine learning: insights from Italian national forest.</em><br/>M. Fasihi, <b>A. Falcon</b>, G. Alberti, L. Cadez, F. Giannetti, A. Tomao, G. Serra. <b>Annals of GIS, 2025.</b> <a href="https://www.tandfonline.com/doi/full/10.1080/19475683.2025.2523737">[pdf]</a></li>
  <li><em>2D Prediction of the Nutritional Composition of Dishes from Food Images: Deep Learning Algorithm Selection and Data Curation Beyond the Nutrition5k Project.</em><br/>R. Bianco, S. Coluccia, M. Marinoni, <b>A. Falcon</b>, F. Fiori, G. Serra, M. Ferraroni, V. Edefonti, M. Parpinel. <b>Nutrients 17(13), 2025.</b> <a href="https://www.mdpi.com/2072-6643/17/13/2196">[pdf]</a></li>
  <li><em>Boosting grapevine phenological stages prediction based on climatic data by pseudo-labeling approach.</em><br/>M. Fasihi, M. Sodini, <b>A. Falcon</b>, F. Degano, P. Sivilotti, G. Serra. <b>Artificial Intelligence in Agriculture 15(3).</b> <a href="https://www.sciencedirect.com/science/article/pii/S2589721725000303">[pdf]</a></li>
  <li><em>Assessing ensemble models for carbon sequestration and storage estimation in forests using remote sensing data.</em><br/>M. Fasihi, B. Portelli, L. Cadez, A. Tomao, A. Falcon, G. Alberti, G. Serra. <b>Ecological Informatics 83, 2024.</b> <a href="https://www.sciencedirect.com/science/article/pii/S1574954124003704">[pdf]</a></li>
</ol>




<h3>Video Question Answering <i class="fa-solid fa-photo-film"></i> <i class="fa-solid fa-person-circle-question"></i> <i class="fa-solid fa-arrow-right"></i> <i class="fa-solid fa-circle-exclamation"></i></h3>
<h5><em>topics: multimedia, cross-modal understanding, vision and language</em></h5>

<img src="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/master/assets/imgs/mtap_vqa.png" alt="Overview of the algorithm" width="50%" height="auto">
<p><b>TL;DR</b>: Given a video and a question about its visual contents, can a model automatically provide the correct answer to that question? We investigated and introduced data augmentation techniques to achieve better accuracy while avoiding costly manual annotations, and proposed customized learning strategies leveraging the contents of the question itself. </p>


<h5>Selected publications/endeavors</h5>
<ol>
  <li><em>Video question answering supported by a multi-task learning objective.</em><br/><b>A. Falcon</b>, G. Serra, O. Lanz. <b>Multimedia Tools and Applications 82 (25), 38799-38826. 2023.</b> <a href="https://link.springer.com/article/10.1007/s11042-023-14333-0">[pdf]</a></li>
  <li><em>Semantics for vision-and-language understanding.</em><br/><b>A. Falcon</b>. PhD Thesis, 2023. <a href="https://air.uniud.it/bitstream/11390/1252364/2/PhD_thesis-4.pdf">[pdf]</a></li>
  <li><em>Data augmentation techniques for the video question answering task.</em><br/><b>A. Falcon</b>, G. Serra, O. Lanz. <b>EPIC@ECCV 2020.</b> <a href="https://arxiv.org/abs/2008.09849">[pdf]</a></li>
</ol>



<h3>Remaining Useful Life Estimation <i class="fa-solid fa-paper-plane"></i> <i class="fa-solid fa-heart-crack"></i> <i class="fa-solid fa-arrow-trend-down"></i> </h3>
<h5><em>topics: predictive maintenance</em></h5>

<img src="https://raw.githubusercontent.com/aranciokov/aranciokov.github.io/master/assets/imgs/aiabi.png" alt="Overview of the algorithm" width="50%" height="auto">
<p><b>TL;DR</b>: We deal with the problem of estimating the remaining useful life (RUL) of mechanical engines (aeroplanes, in particular) by using neural sequence models. The RUL can be seen as a measure of how long it will take for the device under analysis to reach a failure (or, a situation in which a failure is very likely). We introduced to this field of research a neural model inspired from Neural Turing Machines and evaluated them under different scenarios. Experimental results confirm their robustness and precision compared to several neural sequence models.</p>


<h5>Selected publications/endeavors</h5>
<ol>
  <li><em>Neural turing machines for the remaining useful life estimation problem.</em><br/><b>A. Falcon</b>, G. D’Agostino, O. Lanz, G. Brajnik, C. Tasso, G. Serra. <b>Computers in Industry 143, 103762. 2022.</b> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0166361522001592">[pdf]</a></li>
  <li><em>Estimating the Remaining Useful Life via Neural Sequence Models: a Comparative Study.</em><br/>G. D'Agostino, <b>A. Falcon</b>, O. Lanz, G. Brajnik, C. Tasso, G. Serra. <b>AIABI@AIxIA 2022.</b> <a href="https://air.uniud.it/bitstream/11390/1263145/1/paper2.pdf">[pdf]</a></li>
  <li><em>A Dual-Stream architecture based on Neural Turing Machine and Attention for the Remaining Useful Life Estimation problem.</em> <b>A. Falcon</b>, G. D'Agostino, G. Serra, G. Brajnik, C. Tasso.<br/><b>PHME 2020.</b> <a href="https://papers.phmsociety.org/index.php/phme/article/view/1227">[pdf]</a></li>
  <li><em>A neural turing machine-based approach to remaining useful life estimation.</em><br/><b>A. Falcon</b>, G. D'Agostino, G. Serra, G. Brajnik, C. Tasso. <b>ICPHM 2020.</b> <a href="https://ieeexplore.ieee.org/abstract/document/9187043/">[pdf]</a></li>
  <li><em>Remaining Useful Life Estimation using LSTM Networks and Attentive mechanisms.</em><br/><b>A. Falcon</b>. MSc Thesis, 2019.</li>
</ol>



<h2>Academic Service</h2>
<ul>
  <li><em>Proceedings Chair</em>: <a href="https://ceur-ws.org/Vol-3365/">IRCDL 2023</a></li>
  <li><em>Organizer or Part of the Organization Committee</em>: 
    <ul>
      <li>CV4Metaverse at <a href="https://sites.google.com/view/cv4metaverse-2025">CVPR 2025</a> and <a href="https://sites.google.com/view/cv4metaverse-2024">ECCV 2024</a>, </li>
      <li><a href="https://ircdl2025.uniud.it/">IRCDL 2025</a>, </li>
      <li><a href="http://eqai.eu/">EQAI 2025, 2024, 2023</a>, </li>
      <li><a href="https://sites.google.com/view/iciap-2023">ICIAP 2023</a>, </li>
      <li><a href="https://aixia2022.uniud.it/">AIxIA 2022</a>, </li>
      <li><a href="https://sites.google.com/view/viqa2020">VIQA 2020</a>/<a href="https://sites.google.com/view/vtiur2020">VTIUR 2020</a></li>
    </ul>
  </li>
  <li><em>Invited speaker or lecturer</em>:
    <ul>
      <li>"Text-to-Metaverse Retrieval: A New Frontier in Search" at AI-DLDA summer school (2024), </li>
      <li>"Deep Learning for Multimedia understanding" at University of Udine (2023), </li>
      <li>"Data-driven approaches for the Remaining Useful Life Estimation problem" at University of Bolzano (2022), </li>
      <li>"Learning video retrieval models with relevance-aware online mining" at University of Bolzano (2022), </li>
      <li>"Data-driven approaches for the remaining useful life estimation problem" at FBK (2022).</li>
    </ul>
  </li>
  <li><em>Guest associate editor</em>: <a href="https://dl.acm.org/pb-assets/static_journal_pages/tomm/pdf/ACM_SI_Text_Multimedia_Retrieval-1708635324153.pdf">SI on Text-Multimedia Retrieval (ACM TOMM)</a></li>
  <li><em>Journal Reviewing</em>: IJCV, IEEE TMM, CVIU, IET Computer Vision, ACM TOMM, IEEE Trans Hum Mach Syst.</li>
  <li><em>Conference Reviewing</em>: <b>ACM MM</b> 2023-2025, <b>CVPR</b> 2025, <b>ICCV</b> 2025, <b>ACM ICMR</b> 2025, MMM 2025, <b>ECCV</b> 2024 (Outstanding Reviewer!), CCISP 2023, IRCDL 2023, ICIAP 2021-2023, EMNLP 2021, ICPR 2020-2022.</li>
  <li><em>Co-Supervision</em>: 3 Bachelor and 6 Master students of Computer Science Degree or IoT, Big Data, and ML Degree at UniUD on topics related to Video&Language, 3D Scenes Retrieval, and Predictive Maintenance.
    <ul>
      <li>Bazzana Lorenzo, Msc <i class="fa-solid fa-graduation-cap"></i> <em>Enhancing Metaverse Retrieval Effectiveness through Hierarchical Room-Aware Representations</em>. 2025.</li>
      <li>Fedrigo Mattia, Msc <i class="fa-solid fa-graduation-cap"></i> <em>Automating Vegetation Cover Estimation with Deep Learning: A Transfer Learning-Based Semantic Segmentation Approach</em>. 2025.</li>
      <li>Lavarone Stefano, Msc <i class="fa-solid fa-graduation-cap"></i> <em>Design and Evaluation of a Multimodal Retrieval System on a Novel Dataset of Automatically Generated Virtual Museums</em>. 2025.</li>
      <li>Macrì Gianluca, MSc <i class="fa-solid fa-graduation-cap"></i> <em>IA per il retrieval di esibizioni d'arte multimediale per il Metaverso</em>. 2024. (published at <a href="https://doi.org/10.1145/3731715.3733358">ACM ICMR 2025</a>!)</li>
      <li>Gallegos Carvajal Ian Marco, MSc <i class="fa-solid fa-graduation-cap"></i> <em>Enhancing text-to-textured 3D mesh generation with training-free adaptation for textual-visual consistency using spatial constraints and quality assurance: a case study on Text2Room</em>. 2024.</li>
      <li>Rodaro Edoardo, BSc <i class="fa-solid fa-graduation-cap"></i> <em>Rilevamento del flusso di materiale su nastro trasportatore attraverso le reti neurali</em>. 2023.</li>
      <li>Bianchi Carlo, MSc <i class="fa-solid fa-graduation-cap"></i> <em>L'Intelligenza Artificiale a supporto del metaverso</em>. 2023. </li>
      <li>Bruni Pierfrancesco, MSc <i class="fa-solid fa-graduation-cap"></i> <em>Circulant matrices lead to an improved baseline for question-driven video moment localization</em>. 2022. (published at <a href="https://link.springer.com/chapter/10.1007/978-3-031-43153-1_16">IRCDL 2023</a>!) </li>
      <li>De Martin Federica, MSc <i class="fa-solid fa-graduation-cap"></i> <em>Ricerca di un nuovo modello video e transfer learning nell’ambito del Multi-Instance video-text retrieval</em>. 2022. </li>
      <li>De Reggi Paolo, MSc <i class="fa-solid fa-graduation-cap"></i> <em>Generazione automatica di domande e risposte per il problema del video question answering</em>. 2021. </li>
      <li>Ferroli Daniele, BSc <i class="fa-solid fa-graduation-cap"></i> <em>Implementazione di un sistema di Video Question Answering</em>. 2020. </li>
      <li>Rosso Giovanni, BSc <i class="fa-solid fa-graduation-cap"></i> <em>Utilizzo di reti neurali convolutive per la manutenzione predittiva</em>. 2020. </li>
    </ul>
  </li>
</ul>
